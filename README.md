

# Awesome gnns on large-scale graphs 

Papers about methods or graph neural networks (GNNs) on large-scale graphs. Aiming to solve the memory bottleneck problem of GNNs on large-scale graphs, many training strategies such as node-wise, layer-wise, and subgraph sampling are widely explored. In addition, there are also some works designing specific GNNs to solve this problem. 

**Welcome to submit a pull request to add more awesome papers.**

2021

----

* [ICML 2021] GNNAutoScale: Scalable and Expressive Graph Neural Networks via Historical Embeddings. [[paper]](https://arxiv.org/abs/2106.05609)  [[code]](https://github.com/rusty1s/pyg_autoscale) 

2020

----

* [ICLR 2020] GraphSAINT: Graph Sampling Based Inductive Learning Method. [[paper](https://arxiv.org/abs/1907.04931)] [[code](https://github.com/GraphSAINT/GraphSAINT)] 
* [KDD 2020] Minimal Variance Sampling with Provable Guarantees for Fast Training of Graph Neural Networks. [[paper](https://arxiv.org/abs/2006.13866)] 
* [ICML Workshop 2020] SIGN: Scalable Inception Graph Networks. [[paper](https://arxiv.org/abs/2004.11198)] [[code](https://github.com/twitter-research/sign)] 
* [ICML 2020] Simple and Deep Graph Convolutional Networks. [[paper](https://arxiv.org/abs/2007.02133)] [[code](https://github.com/chennnM/GCNII)] 
* [NeurIPS 2020] Scalable Graph Neural Networks via Bidirectional Propagation. [[paper](https://arxiv.org/abs/2010.15421)] [[code](https://github.com/chennnM/GBP)] 

2019

---

* [KDD 2019] Cluster-GCN: An Efficient Algorithm for Training Deep and Large Graph Convolutional Networks. [[paper](https://arxiv.org/abs/1905.07953)] [[TensorFlow](https://github.com/google-research/google-research/tree/34444253e9f57cd03364bc4e50057a5abe9bcf17/cluster_gcn)] [[PyTorch](https://github.com/benedekrozemberczki/ClusterGCN)] 
* [NeurIPS 2019] Layer-Dependent Importance Sampling for Training Deep and Large Graph Convolutional Networks. [[paper](https://arxiv.org/abs/1911.07323)] [[code](https://github.com/acbull/LADIES)] 
* [ICML 2019] Simplifying Graph Convolution Networks. [[paper](https://arxiv.org/abs/1902.07153)] [[code](https://github.com/Tiiiger/SGC)] 

2018

----

* [ICLR 2018] FastGCN: Fast Learning with Graph Convolutional Networks via Importance Sampling. [[paper](https://arxiv.org/abs/1801.10247)] [[code](https://github.com/matenure/FastGCN)] 
* [KDD 2018] Large-Scale Learnable Graph Convolutional Networks. [[paper](https://arxiv.org/abs/1808.03965)] [[code](https://github.com/divelab/lgcn)] 
* [ICML 2018] Stochastic Training of Graph Convolutional Networks with Variance Reduction. [[paper](https://arxiv.org/abs/1710.10568)] [[code](https://github.com/thu-ml/stochastic_gcn)] 
* [NeurIPS 2018] Adaptive Sampling Towards Fast Graph Representation Learning. [[paper](https://arxiv.org/abs/1809.05343)] [[code](https://github.com/huangwb/AS-GCN)] 

2017

---

* [NIPS 2017] Inductive Representation Learning on Large Graphs. [[paper](https://arxiv.org/abs/1706.02216)] [[code](https://github.com/williamleif/GraphSAGE)] 

